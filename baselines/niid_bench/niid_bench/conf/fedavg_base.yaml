---
# this is the config that will be loaded as default by main.py
# Please follow the provided structure (this will ensuring all baseline follow
# a similar configuration structure and hence be easy to customise)

num_clients: 3
num_epochs: 2
batch_size: 16
clients_per_round: 3
learning_rate: 0.01
num_rounds: 30
partitioning: "iid"
dataset_name: "lumpy"
dataset_seed: 42
alpha: 0.5
labels_per_client: 2 # only used when partitioning is label quantity
momentum: 0.9
weight_decay: 0.00001
model_name: xgboost
task: classification

client_fn:
  _target_: niid_bench.client_fedavg.gen_client_fn
  _recursive_: False
  num_epochs: ${num_epochs}
  learning_rate: ${learning_rate}
  momentum: ${momentum}
  weight_decay: ${weight_decay}

dataset:
  # dataset config
  name: ${dataset_name}
  partitioning: ${partitioning}
  batch_size: ${batch_size} # batch_size = batch_size_ratio * total_local_data_size
  val_split: 0.0
  seed: ${dataset_seed}
  alpha: ${alpha}
  labels_per_client: ${labels_per_client}
  frac: 0.2 # fraction of the dataset to use

model:
  # model config
  _target_: niid_bench.models.CNN
  input_dim: None
  hidden_dims: [64, 256, 128, 64]
  output_dim: 62
  task: ${task}
  tabnet: ${tabnet}
  dataset_name: ${dataset_name}
  batch_size: ${batch_size}

strategy:
  _target_: flwr.server.strategy.FedAvg # points to your strategy (either custom or exiting in Flower)
  # rest of strategy config
  fraction_fit: 0.00001 # because we want the number of clients to sample on each round to be solely defined by min_fit_clients
  fraction_evaluate: 0.0
  min_fit_clients: ${clients_per_round}
  min_available_clients: ${clients_per_round}
  min_evaluate_clients: ${clients_per_round}

client:
  # client config

server_device: cuda:0

client_resources:
  num_cpus: 32
  num_gpus: 1.0

xgboost:
  client_tree_num: 5
  num_iterations: 30

tabnet:
  n_d: 2
  n_a: 3
  n_steps: 3
  n_independent: 2
  n_shared: 2
  gamma: 1.3
  momentum: 0.02
  lambda_sparse: 0.001
  lr: 0.02
  step_size: 50
  sch_gamma: 0.9
  mask_type: entmax
  cat_emb_dim: 2
  device_name: ${server_device}
  relaxation_factor: 1.0
  batch_momentum: 0.98
  virtual_batch_size: 16
  norm_type: group
  num_groups: 1